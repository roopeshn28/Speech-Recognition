{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from utils import get_label, extract_feature, get_first_letters\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class AudioExtractor:\n",
    "    \"\"\"A class that is used to featurize audio clips, and provide\n",
    "    them to the machine learning algorithms for training and testing\"\"\"\n",
    "    def __init__(self, audio_config=None, verbose=1, features_folder_name=\"features\", classification=True,\n",
    "                    emotions=['sad', 'neutral', 'happy'], balance=True):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            audio_config (dict): the dictionary that indicates what features to extract from the audio file,\n",
    "                default is {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}\n",
    "                (i.e mfcc, chroma and mel)\n",
    "            verbose (bool/int): verbosity level, 0 for silence, 1 for info, default is 1\n",
    "            features_folder_name (str): the folder to store output features extracted, default is \"features\".\n",
    "            classification (bool): whether it is a classification or regression, default is True (i.e classification)\n",
    "            emotions (list): list of emotions to be extracted, default is ['sad', 'neutral', 'happy']\n",
    "            balance (bool): whether to balance dataset (both training and testing), default is True\n",
    "        \"\"\"\n",
    "        self.audio_config = audio_config if audio_config else {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}\n",
    "        self.verbose = verbose\n",
    "        self.features_folder_name = features_folder_name\n",
    "        self.classification = classification\n",
    "        self.emotions = emotions\n",
    "        self.balance = balance\n",
    "        # input dimension\n",
    "        self.input_dimension = None\n",
    "\n",
    "    def _load_data(self, desc_files, partition, shuffle):\n",
    "        self.load_metadata_from_desc_file(desc_files, partition)\n",
    "        # balancing the datasets ( both training or testing )\n",
    "        if partition == \"train\" and self.balance:\n",
    "            self.balance_training_data()\n",
    "        elif partition == \"test\" and self.balance:\n",
    "            self.balance_testing_data()\n",
    "        else:\n",
    "            if self.balance:\n",
    "                raise TypeError(\"Invalid partition, must be either train/test\")\n",
    "        if shuffle:\n",
    "            self.shuffle_data_by_partition(partition)\n",
    "\n",
    "    def load_train_data(self, desc_files=[\"train_speech.csv\"], shuffle=False):\n",
    "        \"\"\"Loads training data from the metadata files `desc_files`\"\"\"\n",
    "        self._load_data(desc_files, \"train\", shuffle)\n",
    "        \n",
    "    def load_test_data(self, desc_files=[\"test_speech.csv\"], shuffle=False):\n",
    "        \"\"\"Loads testing data from the metadata files `desc_files`\"\"\"\n",
    "        self._load_data(desc_files, \"test\", shuffle)\n",
    "\n",
    "    def shuffle_data_by_partition(self, partition):\n",
    "        if partition == \"train\":\n",
    "            self.train_audio_paths, self.train_emotions, self.train_features = shuffle_data(self.train_audio_paths,\n",
    "            self.train_emotions, self.train_features)\n",
    "        elif partition == \"test\":\n",
    "            self.test_audio_paths, self.test_emotions, self.test_features = shuffle_data(self.test_audio_paths,\n",
    "            self.test_emotions, self.test_features)\n",
    "        else:\n",
    "            raise TypeError(\"Invalid partition, must be either train/test\")\n",
    "\n",
    "    def load_metadata_from_desc_file(self, desc_files, partition):\n",
    "        \"\"\"Read metadata from a CSV file & Extract and loads features of audio files\n",
    "        Params:\n",
    "            desc_files (list): list of description files (csv files) to read from\n",
    "            partition (str): whether is \"train\" or \"test\"\n",
    "        \"\"\"\n",
    "        # empty dataframe\n",
    "        df = pd.DataFrame({'path': [], 'emotion': []})\n",
    "        for desc_file in desc_files:\n",
    "            # concat dataframes\n",
    "            df = pd.concat((df, pd.read_csv(desc_file)), sort=False)\n",
    "        if self.verbose:\n",
    "            print(\"[*] Loading audio file paths and its corresponding labels...\")\n",
    "        # get columns\n",
    "        audio_paths, emotions = list(df['path']), list(df['emotion'])\n",
    "        # if not classification, convert emotions to numbers\n",
    "        if not self.classification:\n",
    "            # so naive and need to be implemented\n",
    "            # in a better way\n",
    "            if len(self.emotions) == 3:\n",
    "                self.categories = {'sad': 1, 'neutral': 2, 'happy': 3}\n",
    "            elif len(self.emotions) == 5:\n",
    "                self.categories = {'angry': 1, 'sad': 2, 'neutral': 3, 'ps': 4, 'happy': 5}\n",
    "            else:\n",
    "                raise TypeError(\"Regression is only for either ['sad', 'neutral', 'happy'] or ['angry', 'sad', 'neutral', 'ps', 'happy']\")\n",
    "            emotions = [ self.categories[e] for e in emotions ]\n",
    "        # make features folder if does not exist\n",
    "        if not os.path.isdir(self.features_folder_name):\n",
    "            os.mkdir(self.features_folder_name)\n",
    "        # get label for features\n",
    "        label = get_label(self.audio_config)\n",
    "        # construct features file name\n",
    "        n_samples = len(audio_paths)\n",
    "        first_letters = get_first_letters(self.emotions)\n",
    "        name = os.path.join(self.features_folder_name, f\"{partition}_{label}_{first_letters}_{n_samples}.npy\")\n",
    "        if os.path.isfile(name):\n",
    "            # if file already exists, just load then\n",
    "            if self.verbose:\n",
    "                print(\"[+] Feature file already exists, loading...\")\n",
    "            features = np.load(name)\n",
    "        else:\n",
    "            # file does not exist, extract those features and dump them into the file\n",
    "            features = []\n",
    "            append = features.append\n",
    "            for audio_file in tqdm.tqdm(audio_paths, f\"Extracting features for {partition}\"):\n",
    "                feature = extract_feature(audio_file, **self.audio_config)\n",
    "                if self.input_dimension is None:\n",
    "                    self.input_dimension = feature.shape[0]\n",
    "                append(feature)\n",
    "            # convert to numpy array\n",
    "            features = np.array(features)\n",
    "            # save it\n",
    "            np.save(name, features)\n",
    "        if partition == \"train\":\n",
    "            try:\n",
    "                self.train_audio_paths\n",
    "            except AttributeError:\n",
    "                self.train_audio_paths = audio_paths\n",
    "                self.train_emotions = emotions\n",
    "                self.train_features = features\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"[*] Adding additional training samples\")\n",
    "                self.train_audio_paths += audio_paths\n",
    "                self.train_emotions += emotions\n",
    "                self.train_features = np.vstack((self.train_features, features))\n",
    "        elif partition == \"test\":\n",
    "            try:\n",
    "                self.test_audio_paths\n",
    "            except AttributeError:\n",
    "                self.test_audio_paths = audio_paths\n",
    "                self.test_emotions = emotions\n",
    "                self.test_features = features\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"[*] Adding additional testing samples\")\n",
    "                self.test_audio_paths += audio_paths\n",
    "                self.test_emotions += emotions\n",
    "                self.test_features = np.vstack((self.test_features, features))\n",
    "        else:\n",
    "            raise TypeError(\"Invalid partition, must be either train/test\")\n",
    "\n",
    "    def _balance_data(self, partition):\n",
    "        if partition == \"train\":\n",
    "            emotions = self.train_emotions\n",
    "            features = self.train_features\n",
    "            audio_paths = self.train_audio_paths\n",
    "        elif partition == \"test\":\n",
    "            emotions = self.test_emotions\n",
    "            features = self.test_features\n",
    "            audio_paths = self.test_audio_paths\n",
    "        else:\n",
    "            raise TypeError(\"Invalid partition, must be either train/test\")\n",
    "        \n",
    "        count = []\n",
    "        if self.classification:\n",
    "            for emotion in self.emotions:\n",
    "                count.append(len([ e for e in emotions if e == emotion]))\n",
    "        else:\n",
    "            # regression, take actual numbers, not label emotion\n",
    "            for emotion in self.categories.values():\n",
    "                count.append(len([ e for e in emotions if e == emotion]))\n",
    "        # get the minimum data samples to balance to\n",
    "        minimum = min(count)\n",
    "        if self.verbose:\n",
    "            print(\"[*] Balancing the dataset to the minimum value:\", minimum)\n",
    "        d = defaultdict(list)\n",
    "        if self.classification:\n",
    "            counter = {e: 0 for e in self.emotions }\n",
    "        else:\n",
    "            counter = { e: 0 for e in self.categories.values() }\n",
    "        for emotion, feature, audio_path in zip(emotions, features, audio_paths):\n",
    "            if counter[emotion] >= minimum:\n",
    "                # minimum value exceeded\n",
    "                continue\n",
    "            counter[emotion] += 1\n",
    "            d[emotion].append((feature, audio_path))\n",
    "\n",
    "        emotions, features, audio_paths = [], [], []\n",
    "        for emotion, features_audio_paths in d.items():\n",
    "            for feature, audio_path in features_audio_paths:\n",
    "                emotions.append(emotion)\n",
    "                features.append(feature)\n",
    "                audio_paths.append(audio_path)\n",
    "        \n",
    "        if partition == \"train\":\n",
    "            self.train_emotions = emotions\n",
    "            self.train_features = features\n",
    "            self.train_audio_paths = audio_paths\n",
    "        elif partition == \"test\":\n",
    "            self.test_emotions = emotions\n",
    "            self.test_features = features\n",
    "            self.test_audio_paths = audio_paths\n",
    "        else:\n",
    "            raise TypeError(\"Invalid partition, must be either train/test\")\n",
    "\n",
    "    def balance_training_data(self):\n",
    "        self._balance_data(\"train\")\n",
    "\n",
    "    def balance_testing_data(self):\n",
    "        self._balance_data(\"test\")\n",
    "        \n",
    "\n",
    "def shuffle_data(audio_paths, emotions, features):\n",
    "    \"\"\" Shuffle the data (called after making a complete pass through \n",
    "        training or validation data during the training process)\n",
    "    Params:\n",
    "        audio_paths (list): Paths to audio clips\n",
    "        emotions (list): Emotions in each audio clip\n",
    "        features (list): features audio clips\n",
    "    \"\"\"\n",
    "    p = np.random.permutation(len(audio_paths))\n",
    "    audio_paths = [audio_paths[i] for i in p] \n",
    "    emotions = [emotions[i] for i in p]\n",
    "    features = [features[i] for i in p]\n",
    "    return audio_paths, emotions, features\n",
    "\n",
    "\n",
    "def load_data(train_desc_files, test_desc_files, audio_config=None, classification=True, shuffle=True,\n",
    "                balance=True, emotions=['sad', 'neutral', 'happy']):\n",
    "    # instantiate the class\n",
    "    audiogen = AudioExtractor(audio_config=audio_config, classification=classification, emotions=emotions,\n",
    "                                balance=balance, verbose=0)\n",
    "    # Loads training data\n",
    "    audiogen.load_train_data(train_desc_files, shuffle=shuffle)\n",
    "    # Loads testing data\n",
    "    audiogen.load_test_data(test_desc_files, shuffle=shuffle)\n",
    "    # X_train, X_test, y_train, y_test\n",
    "    return {\n",
    "        \"X_train\": np.array(audiogen.train_features),\n",
    "        \"X_test\": np.array(audiogen.test_features),\n",
    "        \"y_train\": np.array(audiogen.train_emotions),\n",
    "        \"y_test\": np.array(audiogen.test_emotions),\n",
    "        \"train_audio_paths\": audiogen.train_audio_paths,\n",
    "        \"test_audio_paths\": audiogen.test_audio_paths\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-r REMOVE] audio_path target_path\n",
      "ipykernel_launcher.py: error: the following arguments are required: target_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "A utility script used for converting audio samples to be \n",
    "suitable for feature extraction\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "def convert_audio(audio_path, target_path, remove=False):\n",
    "    \"\"\"This function sets the audio `audio_path` to:\n",
    "        - 16000Hz Sampling rate\n",
    "        - one audio channel ( mono )\n",
    "            Params:\n",
    "                audio_path (str): the path of audio wav file you want to convert\n",
    "                target_path (str): target path to save your new converted wav file\n",
    "                remove (bool): whether to remove the old file after converting\n",
    "        Note that this function requires ffmpeg installed in your system.\"\"\"\n",
    "\n",
    "    os.system(f\"ffmpeg -i {audio_path} -ac 1 -ar 16000 {target_path}\")\n",
    "    # os.system(f\"ffmpeg -i {audio_path} -ac 1 {target_path}\")\n",
    "    if remove:\n",
    "        os.remove(audio_path)\n",
    "\n",
    "\n",
    "def convert_audios(path, target_path, remove=False):\n",
    "    \"\"\"Converts a path of wav files to:\n",
    "        - 16000Hz Sampling rate\n",
    "        - one audio channel ( mono )\n",
    "        and then put them into a new folder called `target_path`\n",
    "            Params:\n",
    "                audio_path (str): the path of audio wav file you want to convert\n",
    "                target_path (str): target path to save your new converted wav file\n",
    "                remove (bool): whether to remove the old file after converting\n",
    "        Note that this function requires ffmpeg installed in your system.\"\"\"\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for dirname in dirnames:\n",
    "            dirname = os.path.join(dirpath, dirname)\n",
    "            target_dir = dirname.replace(path, target_path)\n",
    "            if not os.path.isdir(target_dir):\n",
    "                os.mkdir(target_dir)\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            file = os.path.join(dirpath, filename)\n",
    "            if file.endswith(\".wav\"):\n",
    "                # it is a wav file\n",
    "                target_file = file.replace(path, target_path)\n",
    "                convert_audio(file, target_file, remove=remove)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description=\"\"\"Convert ( compress ) wav files to 16MHz and mono audio channel ( 1 channel )\n",
    "                                                    This utility helps for compressing wav files for training and testing\"\"\")\n",
    "    parser.add_argument(\"audio_path\", help=\"Folder that contains wav files you want to convert\")\n",
    "    parser.add_argument(\"target_path\", help=\"Folder to save new wav files\")\n",
    "    parser.add_argument(\"-r\", \"--remove\", type=bool, help=\"Whether to remove the old wav file after converting\", default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    audio_path = args.audio_path\n",
    "    target_path = args.target_path\n",
    "\n",
    "    if os.path.isdir(audio_path):\n",
    "        if not os.path.isdir(target_path):\n",
    "            os.makedirs(target_path)\n",
    "            convert_audios(audio_path, target_path, remove=args.remove)\n",
    "    elif os.path.isfile(audio_path) and audio_path.endswith(\".wav\"):\n",
    "        if not target_path.endswith(\".wav\"):\n",
    "            target_path += \".wav\"\n",
    "        convert_audio(audio_path, target_path, remove=args.remove)\n",
    "    else:\n",
    "        raise TypeError(\"The audio_path file you specified isn't appropriate for this operation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def write_emodb_csv(emotions=[\"sad\", \"neutral\", \"happy\"], train_name=\"train_emo.csv\",\n",
    "                    test_name=\"test_emo.csv\", train_size=0.8, verbose=1):\n",
    "    \"\"\"\n",
    "    Reads speech emodb dataset from directory and write it to a metadata CSV file.\n",
    "    params:\n",
    "        emotions (list): list of emotions to read from the folder, default is ['sad', 'neutral', 'happy']\n",
    "        train_name (str): the output csv filename for training data, default is 'train_emo.csv'\n",
    "        test_name (str): the output csv filename for testing data, default is 'test_emo.csv'\n",
    "        train_size (float): the ratio of splitting training data, default is 0.8 (80% Training data and 20% testing data)\n",
    "        verbose (int/bool): verbositiy level, 0 for silence, 1 for info, default is 1\n",
    "    \"\"\"\n",
    "    target = {\"path\": [], \"emotion\": []}\n",
    "    categories = {\n",
    "        \"W\": \"angry\",\n",
    "        \"L\": \"boredom\",\n",
    "        \"E\": \"disgust\",\n",
    "        \"A\": \"fear\",\n",
    "        \"F\": \"happy\",\n",
    "        \"T\": \"sad\",\n",
    "        \"N\": \"neutral\"\n",
    "    }\n",
    "    # delete not specified emotions\n",
    "    categories_reversed = { v: k for k, v in categories.items() }\n",
    "    for emotion, code in categories_reversed.items():\n",
    "        if emotion not in emotions:\n",
    "            del categories[code]\n",
    "    for file in glob.glob(\"data/emodb/wav/*.wav\"):\n",
    "        try:\n",
    "            emotion = categories[os.path.basename(file)[5]]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        target['emotion'].append(emotion)\n",
    "        target['path'].append(file)\n",
    "    if verbose:\n",
    "        print(\"[EMO-DB] Total files to write:\", len(target['path']))\n",
    "        \n",
    "    # dividing training/testing sets\n",
    "    n_samples = len(target['path'])\n",
    "    test_size = int((1-train_size) * n_samples)\n",
    "    train_size = int(train_size * n_samples)\n",
    "    if verbose:\n",
    "        print(\"[EMO-DB] Training samples:\", train_size)\n",
    "        print(\"[EMO-DB] Testing samples:\", test_size)   \n",
    "    X_train = target['path'][:train_size]\n",
    "    X_test = target['path'][train_size:]\n",
    "    y_train = target['emotion'][:train_size]\n",
    "    y_test = target['emotion'][train_size:]\n",
    "    pd.DataFrame({\"path\": X_train, \"emotion\": y_train}).to_csv(train_name)\n",
    "    pd.DataFrame({\"path\": X_test, \"emotion\": y_test}).to_csv(test_name)\n",
    "\n",
    "\n",
    "def write_tess_ravdess_csv(emotions=[\"sad\", \"neutral\", \"happy\"], train_name=\"train_tess_ravdess.csv\",\n",
    "                            test_name=\"test_tess_ravdess.csv\", verbose=1):\n",
    "    \"\"\"\n",
    "    Reads speech TESS & RAVDESS datasets from directory and write it to a metadata CSV file.\n",
    "    params:\n",
    "        emotions (list): list of emotions to read from the folder, default is ['sad', 'neutral', 'happy']\n",
    "        train_name (str): the output csv filename for training data, default is 'train_tess_ravdess.csv'\n",
    "        test_name (str): the output csv filename for testing data, default is 'test_tess_ravdess.csv'\n",
    "        verbose (int/bool): verbositiy level, 0 for silence, 1 for info, default is 1\n",
    "    \"\"\"\n",
    "    train_target = {\"path\": [], \"emotion\": []}\n",
    "    test_target = {\"path\": [], \"emotion\": []}\n",
    "    \n",
    "    for category in emotions:\n",
    "        # for training speech directory\n",
    "        for i, path in enumerate(glob.glob(f\"data/training/Actor_*/*_{category}.wav\")):\n",
    "            train_target[\"path\"].append(path)\n",
    "            train_target[\"emotion\"].append(category)\n",
    "        if verbose:\n",
    "            print(f\"[TESS&RAVDESS] There are {i} training audio files for category:{category}\")\n",
    "    \n",
    "        # for validation speech directory\n",
    "        for i, path in enumerate(glob.glob(f\"data/validation/Actor_*/*_{category}.wav\")):\n",
    "            test_target[\"path\"].append(path)\n",
    "            test_target[\"emotion\"].append(category)\n",
    "        if verbose:\n",
    "            print(f\"[TESS&RAVDESS] There are {i} testing audio files for category:{category}\")\n",
    "    pd.DataFrame(test_target).to_csv(test_name)\n",
    "    pd.DataFrame(train_target).to_csv(train_name)\n",
    "\n",
    "\n",
    "def write_custom_csv(emotions=['sad', 'neutral', 'happy'], train_name=\"train_custom.csv\", test_name=\"test_custom.csv\",\n",
    "                    verbose=1):\n",
    "    \"\"\"\n",
    "    Reads Custom Audio data from data/*-custom and then writes description files (csv)\n",
    "    params:\n",
    "        emotions (list): list of emotions to read from the folder, default is ['sad', 'neutral', 'happy']\n",
    "        train_name (str): the output csv filename for training data, default is 'train_custom.csv'\n",
    "        test_name (str): the output csv filename for testing data, default is 'test_custom.csv'\n",
    "        verbose (int/bool): verbositiy level, 0 for silence, 1 for info, default is 1\n",
    "    \"\"\"\n",
    "    train_target = {\"path\": [], \"emotion\": []}\n",
    "    test_target = {\"path\": [], \"emotion\": []}\n",
    "    for category in emotions:\n",
    "        # train data\n",
    "        for i, file in enumerate(glob.glob(f\"data/train-custom/*_{category}.wav\")):\n",
    "            train_target[\"path\"].append(file)\n",
    "            train_target[\"emotion\"].append(category)\n",
    "        if verbose:\n",
    "            try:\n",
    "                print(f\"[Custom Dataset] There are {i} training audio files for category:{category}\")\n",
    "            except NameError:\n",
    "                # in case {i} doesn't exist\n",
    "                pass\n",
    "        \n",
    "        # test data\n",
    "        for i, file in enumerate(glob.glob(f\"data/test-custom/*_{category}.wav\")):\n",
    "            test_target[\"path\"].append(file)\n",
    "            test_target[\"emotion\"].append(category)\n",
    "        if verbose:\n",
    "            try:\n",
    "                print(f\"[Custom Dataset] There are {i} testing audio files for category:{category}\")\n",
    "            except NameError:\n",
    "                pass\n",
    "    \n",
    "    # write CSVs\n",
    "    if train_target[\"path\"]:\n",
    "        pd.DataFrame(train_target).to_csv(train_name)\n",
    "\n",
    "    if test_target[\"path\"]:\n",
    "        pd.DataFrame(test_target).to_csv(test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deep Emotion Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5264fcce1a80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     rec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'],\n\u001b[1;32m--> 406\u001b[1;33m                                 epochs=300, verbose=0)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5264fcce1a80>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# compute the input length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_input_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# boolean attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5264fcce1a80>\u001b[0m in \u001b[0;36m_compute_input_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5264fcce1a80>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mX_test_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable keras loggings\n",
    "import sys\n",
    "stderr = sys.stderr\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "import keras\n",
    "sys.stderr = stderr\n",
    "# to use CPU uncomment below code\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# disable tensorflow logs\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=5,\n",
    "                        inter_op_parallelism_threads=5, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 0}\n",
    "                       )\n",
    "from keras.layers import LSTM, GRU, Dense, Activation, LeakyReLU, Dropout\n",
    "from keras.layers import Conv1D, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, confusion_matrix\n",
    "\n",
    "from data_extractor import load_data\n",
    "from create_csv import write_custom_csv, write_emodb_csv, write_tess_ravdess_csv\n",
    "from emotion_recognition import EmotionRecognizer\n",
    "from utils import get_first_letters, AVAILABLE_EMOTIONS, extract_feature, get_dropout_str\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class DeepEmotionRecognizer(EmotionRecognizer):\n",
    "    \"\"\"\n",
    "    The Deep Learning version of the Emotion Recognizer.\n",
    "    This class uses RNN (LSTM, GRU, etc.) and Dense layers.\n",
    "    #TODO add CNNs\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            emotions (list): list of emotions to be used. Note that these emotions must be available in\n",
    "                RAVDESS_TESS & EMODB Datasets, available nine emotions are the following:\n",
    "                    'neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust', 'ps' ( pleasant surprised ), 'boredom'.\n",
    "                Default is [\"sad\", \"neutral\", \"happy\"].\n",
    "            tess_ravdess (bool): whether to use TESS & RAVDESS Speech datasets, default is True.\n",
    "            emodb (bool): whether to use EMO-DB Speech dataset, default is True.\n",
    "            custom_db (bool): whether to use custom Speech dataset that is located in `data/train-custom`\n",
    "                and `data/test-custom`, default is True.\n",
    "            tess_ravdess_name (str): the name of the output CSV file for TESS&RAVDESS dataset, default is \"tess_ravdess.csv\".\n",
    "            emodb_name (str): the name of the output CSV file for EMO-DB dataset, default is \"emodb.csv\".\n",
    "            custom_db_name (str): the name of the output CSV file for the custom dataset, default is \"custom.csv\".\n",
    "            features (list): list of speech features to use, default is [\"mfcc\", \"chroma\", \"mel\"]\n",
    "                (i.e MFCC, Chroma and MEL spectrogram ).\n",
    "            classification (bool): whether to use classification or regression, default is True.\n",
    "            balance (bool): whether to balance the dataset ( both training and testing ), default is True.\n",
    "            verbose (bool/int): whether to print messages on certain tasks.\n",
    "            ==========================================================\n",
    "            Model params\n",
    "            n_rnn_layers (int): number of RNN layers, default is 2.\n",
    "            cell (keras.layers.RNN instance): RNN cell used to train the model, default is LSTM.\n",
    "            rnn_units (int): number of units of `cell`, default is 128.\n",
    "            n_dense_layers (int): number of Dense layers, default is 2.\n",
    "            dense_units (int): number of units of the Dense layers, default is 128.\n",
    "            dropout (list/float): dropout rate,\n",
    "                - if list, it indicates the dropout rate of each layer.\n",
    "                - if float, it indicates the dropout rate for all layers.\n",
    "                Default is 0.3.\n",
    "            ==========================================================\n",
    "            Training params\n",
    "            batch_size (int): number of samples per gradient update, default is 64.\n",
    "            epochs (int): number of epochs, default is 1000.\n",
    "            optimizer (str/keras.optimizers.Optimizer instance): optimizer used to train, default is \"adam\".\n",
    "            loss (str/callback from keras.losses): loss function that is used to minimize during training,\n",
    "                default is \"categorical_crossentropy\" for classification and \"mean_squared_error\" for \n",
    "                regression.\n",
    "        \"\"\"\n",
    "        # init EmotionRecognizer\n",
    "        super().__init__(None, **kwargs)\n",
    "\n",
    "        self.n_rnn_layers = kwargs.get(\"n_rnn_layers\", 2)\n",
    "        self.n_dense_layers = kwargs.get(\"n_dense_layers\", 2)\n",
    "        self.rnn_units = kwargs.get(\"rnn_units\", 128)\n",
    "        self.dense_units = kwargs.get(\"dense_units\", 128)\n",
    "        self.cell = kwargs.get(\"cell\", LSTM)\n",
    "\n",
    "        # list of dropouts of each layer\n",
    "        # must be len(dropouts) = n_rnn_layers + n_dense_layers\n",
    "        self.dropout = kwargs.get(\"dropout\", 0.3)\n",
    "        self.dropout = self.dropout if isinstance(self.dropout, list) else [self.dropout] * ( self.n_rnn_layers + self.n_dense_layers )\n",
    "        # number of classes ( emotions )\n",
    "        self.output_dim = len(self.emotions)\n",
    "\n",
    "        # optimization attributes\n",
    "        self.optimizer = kwargs.get(\"optimizer\", \"adam\")\n",
    "        self.loss = kwargs.get(\"loss\", \"categorical_crossentropy\")\n",
    "\n",
    "        # training attributes\n",
    "        self.batch_size = kwargs.get(\"batch_size\", 64)\n",
    "        self.epochs = kwargs.get(\"epochs\", 1000)\n",
    "        \n",
    "        # the name of the model\n",
    "        self.model_name = \"\"\n",
    "        self._update_model_name()\n",
    "\n",
    "        # init the model\n",
    "        self.model = None\n",
    "\n",
    "        # compute the input length\n",
    "        self._compute_input_length()\n",
    "\n",
    "        # boolean attributes\n",
    "        self.model_created = False\n",
    "\n",
    "    def _update_model_name(self):\n",
    "        \"\"\"\n",
    "        Generates a unique model name based on parameters passed and put it on `self.model_name`.\n",
    "        This is used when saving the model.\n",
    "        \"\"\"\n",
    "        # get first letters of emotions, for instance:\n",
    "        # [\"sad\", \"neutral\", \"happy\"] => 'HNS' (sorted alphabetically)\n",
    "        emotions_str = get_first_letters(self.emotions)\n",
    "        # 'c' for classification & 'r' for regression\n",
    "        problem_type = 'c' if self.classification else 'r'\n",
    "        dropout_str = get_dropout_str(self.dropout, n_layers=self.n_dense_layers + self.n_rnn_layers)\n",
    "        self.model_name = f\"{emotions_str}-{problem_type}-{self.cell.__name__}-layers-{self.n_rnn_layers}-{self.n_dense_layers}-units-{self.rnn_units}-{self.dense_units}-dropout-{dropout_str}.h5\"\n",
    "\n",
    "    def _get_model_filename(self):\n",
    "        \"\"\"Returns the relative path of this model name\"\"\"\n",
    "        return f\"results/{self.model_name}\"\n",
    "\n",
    "    def _model_exists(self):\n",
    "        \"\"\"\n",
    "        Checks if model already exists in disk, returns the filename,\n",
    "        and returns `None` otherwise.\n",
    "        \"\"\"\n",
    "        filename = self._get_model_filename()\n",
    "        return filename if os.path.isfile(filename) else None\n",
    "\n",
    "    def _compute_input_length(self):\n",
    "        \"\"\"\n",
    "        Calculates the input shape to be able to construct the model.\n",
    "        \"\"\"\n",
    "        if not self.data_loaded:\n",
    "            self.load_data()\n",
    "        self.input_length = self.X_train[0].shape[1]\n",
    "\n",
    "    def _verify_emotions(self):\n",
    "        super()._verify_emotions()\n",
    "        self.int2emotions = {i: e for i, e in enumerate(self.emotions)}\n",
    "        self.emotions2int = {v: k for k, v in self.int2emotions.items()}\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Constructs the neural network based on parameters passed.\n",
    "        \"\"\"\n",
    "        if self.model_created:\n",
    "            # model already created, why call twice\n",
    "            return\n",
    "\n",
    "        if not self.data_loaded:\n",
    "            # if data isn't loaded yet, load it\n",
    "            self.load_data()\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        # rnn layers\n",
    "        for i in range(self.n_rnn_layers):\n",
    "            if i == 0:\n",
    "                # first layer\n",
    "                model.add(self.cell(self.rnn_units, return_sequences=True, input_shape=(None, self.input_length)))\n",
    "                model.add(Dropout(self.dropout[i]))\n",
    "            else:\n",
    "                # middle layers\n",
    "                model.add(self.cell(self.rnn_units, return_sequences=True))\n",
    "                model.add(Dropout(self.dropout[i]))\n",
    "\n",
    "        if self.n_rnn_layers == 0:\n",
    "            i = 0\n",
    "\n",
    "        # dense layers\n",
    "        for j in range(self.n_dense_layers):\n",
    "            # if n_rnn_layers = 0, only dense\n",
    "            if self.n_rnn_layers == 0 and j == 0:\n",
    "                model.add(Dense(self.dense_units, input_shape=(None, self.input_length)))\n",
    "                model.add(Dropout(self.dropout[i+j]))\n",
    "            else:\n",
    "                model.add(Dense(self.dense_units))\n",
    "                model.add(Dropout(self.dropout[i+j]))\n",
    "                \n",
    "        if self.classification:\n",
    "            model.add(Dense(self.output_dim, activation=\"softmax\"))\n",
    "            model.compile(loss=self.loss, metrics=[\"accuracy\"], optimizer=self.optimizer)\n",
    "        else:\n",
    "            model.add(Dense(1, activation=\"linear\"))\n",
    "            model.compile(loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"], optimizer=self.optimizer)\n",
    "        \n",
    "        self.model = model\n",
    "        self.model_created = True\n",
    "        if self.verbose > 0:\n",
    "            print(\"[+] Model created\")\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads and extracts features from the audio files for the db's specified.\n",
    "        And then reshapes the data.\n",
    "        \"\"\"\n",
    "        super().load_data()\n",
    "        # reshape X's to 3 dims\n",
    "        X_train_shape = self.X_train.shape\n",
    "        X_test_shape = self.X_test.shape\n",
    "        self.X_train = self.X_train.reshape((1, X_train_shape[0], X_train_shape[1]))\n",
    "        self.X_test = self.X_test.reshape((1, X_test_shape[0], X_test_shape[1]))\n",
    "\n",
    "        if self.classification:\n",
    "            # one-hot encode when its classification\n",
    "            self.y_train = to_categorical([ self.emotions2int[str(e)] for e in self.y_train ])\n",
    "            self.y_test = to_categorical([ self.emotions2int[str(e)] for e in self.y_test ])\n",
    "        \n",
    "        # reshape labels\n",
    "        y_train_shape = self.y_train.shape\n",
    "        y_test_shape = self.y_test.shape\n",
    "        if self.classification:\n",
    "            self.y_train = self.y_train.reshape((1, y_train_shape[0], y_train_shape[1]))    \n",
    "            self.y_test = self.y_test.reshape((1, y_test_shape[0], y_test_shape[1]))\n",
    "        else:\n",
    "            self.y_train = self.y_train.reshape((1, y_train_shape[0], 1))\n",
    "            self.y_test = self.y_test.reshape((1, y_test_shape[0], 1))\n",
    "\n",
    "    def train(self, override=False):\n",
    "        \"\"\"\n",
    "        Trains the neural network.\n",
    "        Params:\n",
    "            override (bool): whether to override the previous identical model, can be used\n",
    "                when you changed the dataset, default is False\n",
    "        \"\"\"\n",
    "        # if model isn't created yet, create it\n",
    "        if not self.model_created:\n",
    "            self.create_model()\n",
    "\n",
    "        # if the model already exists and trained, just load the weights and return\n",
    "        # but if override is True, then just skip loading weights\n",
    "        if not override:\n",
    "            model_name = self._model_exists()\n",
    "            if model_name:\n",
    "                self.model.load_weights(model_name)\n",
    "                self.model_trained = True\n",
    "                if self.verbose > 0:\n",
    "                    print(\"[*] Model weights loaded\")\n",
    "                return\n",
    "        \n",
    "        if not os.path.isdir(\"results\"):\n",
    "            os.mkdir(\"results\")\n",
    "\n",
    "        if not os.path.isdir(\"logs\"):\n",
    "            os.mkdir(\"logs\")\n",
    "\n",
    "        model_filename = self._get_model_filename()\n",
    "\n",
    "        self.checkpointer = ModelCheckpoint(model_filename, save_best_only=True, verbose=1)\n",
    "        self.tensorboard = TensorBoard(log_dir=f\"logs/{self.model_name}\")\n",
    "\n",
    "        self.history = self.model.fit(self.X_train, self.y_train,\n",
    "                        batch_size=self.batch_size,\n",
    "                        epochs=self.epochs,\n",
    "                        validation_data=(self.X_test, self.y_test),\n",
    "                        callbacks=[self.checkpointer, self.tensorboard],\n",
    "                        verbose=self.verbose)\n",
    "        \n",
    "        self.model_trained = True\n",
    "        if self.verbose > 0:\n",
    "            print(\"[+] Model trained\")\n",
    "\n",
    "    def predict(self, audio_path):\n",
    "        feature = extract_feature(audio_path, **self.audio_config).reshape((1, 1, self.input_length))\n",
    "        if self.classification:\n",
    "            return self.int2emotions[self.model.predict_classes(feature)[0][0]]\n",
    "        else:\n",
    "            return self.model.predict(feature)[0][0][0]\n",
    "\n",
    "    def predict_proba(self, audio_path):\n",
    "        if self.classification:\n",
    "            feature = extract_feature(audio_path, **self.audio_config).reshape((1, 1, self.input_length))\n",
    "            proba = self.model.predict(feature)[0][0]\n",
    "            result = {}\n",
    "            for prob, emotion in zip(proba, self.emotions):\n",
    "                result[emotion] = prob\n",
    "            return result\n",
    "        else:\n",
    "            raise NotImplementedError(\"Probability prediction doesn't make sense for regression\")\n",
    "\n",
    "\n",
    "\n",
    "    def test_score(self):\n",
    "        y_test = self.y_test[0]\n",
    "        if self.classification:\n",
    "            y_pred = self.model.predict_classes(self.X_test)[0]\n",
    "            y_test = [np.argmax(y, out=None, axis=None) for y in y_test]\n",
    "            return accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        else:\n",
    "            y_pred = self.model.predict(self.X_test)[0]\n",
    "            return mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "    def train_score(self):\n",
    "        y_train = self.y_train[0]\n",
    "        if self.classification:\n",
    "            y_pred = self.model.predict_classes(self.X_train)[0]\n",
    "            y_train = [np.argmax(y, out=None, axis=None) for y in y_train]\n",
    "            return accuracy_score(y_true=y_train, y_pred=y_pred)\n",
    "        else:\n",
    "            y_pred = self.model.predict(self.X_train)[0]\n",
    "            return mean_absolute_error(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "    def confusion_matrix(self, percentage=True, labeled=True):\n",
    "        \"\"\"Compute confusion matrix to evaluate the test accuracy of the classification\"\"\"\n",
    "        if not self.classification:\n",
    "            raise NotImplementedError(\"Confusion matrix works only when it is a classification problem\")\n",
    "        y_pred = self.model.predict_classes(self.X_test)[0]\n",
    "        # invert from keras.utils.to_categorical\n",
    "        y_test = np.array([ np.argmax(y, axis=None, out=None) for y in self.y_test[0] ])\n",
    "        matrix = confusion_matrix(y_test, y_pred, labels=[self.emotions2int[e] for e in self.emotions]).astype(np.float32)\n",
    "        if percentage:\n",
    "            for i in range(len(matrix)):\n",
    "                matrix[i] = matrix[i] / np.sum(matrix[i])\n",
    "            # make it percentage\n",
    "            matrix *= 100\n",
    "        if labeled:\n",
    "            matrix = pd.DataFrame(matrix, index=[ f\"true_{e}\" for e in self.emotions ],\n",
    "                                    columns=[ f\"predicted_{e}\" for e in self.emotions ])\n",
    "        return matrix\n",
    "\n",
    "    def n_emotions(self, emotion, partition):\n",
    "        \"\"\"Returns number of `emotion` data samples in a particular `partition`\n",
    "        ('test' or 'train')\n",
    "        \"\"\"\n",
    "        if partition == \"test\":\n",
    "            if self.classification:\n",
    "                y_test = np.array([ np.argmax(y, axis=None, out=None)+1 for y in np.squeeze(self.y_test) ]) \n",
    "            else:\n",
    "                y_test = np.squeeze(self.y_test)\n",
    "            return len([y for y in y_test if y == emotion])\n",
    "        elif partition == \"train\":\n",
    "            if self.classification:\n",
    "                y_train = np.array([ np.argmax(y, axis=None, out=None)+1 for y in np.squeeze(self.y_train) ])\n",
    "            else:\n",
    "                y_train = np.squeeze(self.y_train)\n",
    "            return len([y for y in y_train if y == emotion])\n",
    "\n",
    "    def get_samples_by_class(self):\n",
    "        \"\"\"\n",
    "        Returns a dataframe that contains the number of training \n",
    "        and testing samples for all emotions\n",
    "        \"\"\"\n",
    "        train_samples = []\n",
    "        test_samples = []\n",
    "        total = []\n",
    "        for emotion in self.emotions:\n",
    "            n_train = self.n_emotions(self.emotions2int[emotion]+1, \"train\")\n",
    "            n_test = self.n_emotions(self.emotions2int[emotion]+1, \"test\")\n",
    "            train_samples.append(n_train)\n",
    "            test_samples.append(n_test)\n",
    "            total.append(n_train + n_test)\n",
    "        \n",
    "        # get total\n",
    "        total.append(sum(train_samples) + sum(test_samples))\n",
    "        train_samples.append(sum(train_samples))\n",
    "        test_samples.append(sum(test_samples))\n",
    "        return pd.DataFrame(data={\"train\": train_samples, \"test\": test_samples, \"total\": total}, index=self.emotions + [\"total\"])\n",
    "\n",
    "    def get_random_emotion(self, emotion, partition=\"train\"):\n",
    "        \"\"\"\n",
    "        Returns random `emotion` data sample index on `partition`\n",
    "        \"\"\"\n",
    "        if partition == \"train\":\n",
    "            y_train = self.y_train[0]\n",
    "            index = random.choice(list(range(len(y_train))))\n",
    "            element = self.int2emotions[np.argmax(y_train[index])]\n",
    "            while element != emotion:\n",
    "                index = random.choice(list(range(len(y_train))))\n",
    "                element = self.int2emotions[np.argmax(y_train[index])]\n",
    "        elif partition == \"test\":\n",
    "            y_test = self.y_test[0]\n",
    "            index = random.choice(list(range(len(y_test))))\n",
    "            element = self.int2emotions[np.argmax(y_test[index])]\n",
    "            while element != emotion:\n",
    "                index = random.choice(list(range(len(y_test))))\n",
    "                element = self.int2emotions[np.argmax(y_test[index])]\n",
    "        else:\n",
    "            raise TypeError(\"Unknown partition, only 'train' or 'test' is accepted\")\n",
    "\n",
    "        return index\n",
    "\n",
    "    def determine_best_model(self, train=True):\n",
    "        # TODO\n",
    "        raise TypeError(\"This method isn't supported yet for deep nn\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'],\n",
    "                                epochs=300, verbose=0)\n",
    "    rec.train(override=False)\n",
    "    print(\"Test accuracy score:\", rec.test_score() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TESS&RAVDESS] There are 244 training audio files for category:sad\n",
      "[TESS&RAVDESS] There are 244 testing audio files for category:sad\n",
      "[TESS&RAVDESS] There are 123 training audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 123 testing audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 239 training audio files for category:happy\n",
      "[TESS&RAVDESS] There are 239 testing audio files for category:happy\n",
      "[+] Writed TESS & RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 212\n",
      "[EMO-DB] Training samples: 169\n",
      "[EMO-DB] Testing samples: 42\n",
      "[+] Writed EMO-DB CSV File\n",
      "[Custom Dataset] There are 20 training audio files for category:sad\n",
      "[Custom Dataset] There are 15 testing audio files for category:sad\n",
      "[Custom Dataset] There are 68 training audio files for category:neutral\n",
      "[Custom Dataset] There are 55 testing audio files for category:neutral\n",
      "[Custom Dataset] There are 70 training audio files for category:happy\n",
      "[Custom Dataset] There are 43 testing audio files for category:happy\n",
      "[+] Writed Custom DB CSV File\n",
      "[+] Data loaded\n",
      "Fitting 3 folds for each of 84 candidates, totalling 252 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'break_ties'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n    *args, **kwargs)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 205, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 52, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"C:\\Users\\roopeshn\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 585, in predict\n    if self.break_ties and self.decision_function_shape == 'ovo':\nAttributeError: 'SVC' object has no attribute 'break_ties'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f3558ac6486a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmotionRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memotions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mbest_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_best_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mbest_estimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_best_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{emotions} {best_estimator.__class__.__name__} achieved {cv_best_score:.3f} cross validation accuracy score!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\emotion_recognition.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(self, params, n_jobs)\u001b[0m\n\u001b[0;32m    196\u001b[0m         grid = GridSearchCV(estimator=self.model, param_grid=params, scoring=make_scorer(score),\n\u001b[0;32m    197\u001b[0m                             n_jobs=n_jobs, verbose=1, cv=3)\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                                                        \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[1;32m--> 687\u001b[1;33m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m    689\u001b[0m                                           cv.split(X, y, groups)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                     \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                     \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m                                     \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m                                     verbose=self.verbose)\n\u001b[0;32m    668\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'break_ties'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A script to grid search all parameters provided in parameters.py\n",
    "including both classifiers and regressors.\n",
    "Note that the execution of this script may take hours to search the \n",
    "best possible model parameters for various algorithms, feel free\n",
    "to edit parameters.py on your need ( e.g remove some parameters for \n",
    "faster search )\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from emotion_recognition import EmotionRecognizer\n",
    "from parameters import classification_grid_parameters, regression_grid_parameters\n",
    "\n",
    "emotions = ['sad', 'neutral', 'happy']\n",
    "\n",
    "best_estimators = []\n",
    "\n",
    "for model, params in classification_grid_parameters.items():\n",
    "    if model.__class__.__name__ == \"KNeighborsClassifier\":\n",
    "        # in case of a K-Nearest neighbors algorithm\n",
    "        # set number of neighbors to the length of emotions\n",
    "        params['n_neighbors'] = [len(emotions)]\n",
    "    d = EmotionRecognizer(model, emotions=emotions)\n",
    "    d.load_data()\n",
    "    best_estimator, best_params, cv_best_score = d.grid_search(params=params)\n",
    "    best_estimators.append((best_estimator, best_params, cv_best_score))\n",
    "    print(f\"{emotions} {best_estimator.__class__.__name__} achieved {cv_best_score:.3f} cross validation accuracy score!\")\n",
    "\n",
    "print(f\"[+] Pickling best classifiers for {emotions}...\")\n",
    "filename = \"E:\\MTECH\\Assignments\\AI\\filenames.pkl\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "pickle.dump(best_estimators, open(f\"filename\", \"wb\"))\n",
    "\n",
    "best_estimators = []\n",
    "\n",
    "for model, params in regression_grid_parameters.items():\n",
    "    if model.__class__.__name__ == \"KNeighborsRegressor\":\n",
    "        # in case of a K-Nearest neighbors algorithm\n",
    "        # set number of neighbors to the length of emotions\n",
    "        params['n_neighbors'] = [len(emotions)]\n",
    "    d = EmotionRecognizer(model, emotions=emotions, classification=False)\n",
    "    d.load_data()\n",
    "    best_estimator, best_params, cv_best_score = d.grid_search(params=params)\n",
    "    best_estimators.append((best_estimator, best_params, cv_best_score))\n",
    "    print(f\"{emotions} {best_estimator.__class__.__name__} achieved {cv_best_score:.3f} cross validation MAE score!\")\n",
    "\n",
    "print(f\"[+] Pickling best regressors for {emotions}...\")\n",
    "pickle.dump(best_estimators, open(f\"grid/best_regressors.pickle\", \"wb\"))\n",
    "\n",
    "\n",
    "\n",
    "# Best for SVC: C=0.001, gamma=0.001, kernel='poly'\n",
    "# Best for AdaBoostClassifier: {'algorithm': 'SAMME', 'learning_rate': 0.8, 'n_estimators': 60}\n",
    "# Best for RandomForestClassifier: {'max_depth': 7, 'max_features': 0.5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 40}\n",
    "# Best for GradientBoostingClassifier: {'learning_rate': 0.3, 'max_depth': 7, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 70, 'subsample': 0.7}\n",
    "# Best for DecisionTreeClassifier: {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "# Best for KNeighborsClassifier: {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
    "# Best for MLPClassifier: {'alpha': 0.005, 'batch_size': 256, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive', 'max_iter': 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
